{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LikhanInSpace/Pripyat/blob/main/Resnet%20likhan%20version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joA3t7YQLGVO"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asWonMUmocVx",
        "outputId": "338973fd-de9f-463a-cd4a-c2763af7ccf7"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBUAX-coiQG"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMZapwf6zhX4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx8QQpq6zrmB",
        "outputId": "bec97835-ff8e-4fef-e0f0-1fab6018625c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AD1rDG_0Ep2"
      },
      "source": [
        "# resize images \n",
        "img_size = [224,224]\n",
        "train_path = '/content/drive/MyDrive/real vs fake/train'\n",
        "valid_path = '/content/drive/MyDrive/real vs fake/test'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhw_Whtd0k6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823458d0-cbda-484d-e270-a747444424b3"
      },
      "source": [
        "#Implementing ResNet built in function within Keras\n",
        "#Pretrained on ImageNet weights\n",
        "res = ResNet50(include_top=False, weights= 'imagenet',input_shape= img_size+ [3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRoOAzJF9cKe"
      },
      "source": [
        "for layer in res.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXLvkR6LaGd2"
      },
      "source": [
        "folders = glob('/content/drive/MyDrive/real vs fake/train/*')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1g_bnWKymbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea1774b-b5ac-4077-8f2d-6d9f92a1b4d6"
      },
      "source": [
        "folders"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/real vs fake/train/real',\n",
              " '/content/drive/MyDrive/real vs fake/train/fake']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSf9TSn7yoaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3249e7-0667-43bd-b1c0-0c662b06faac"
      },
      "source": [
        "len(folders)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4tLZxcy4UR"
      },
      "source": [
        "x = Flatten()(res.output)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awpiLoWY2T5H"
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=res.input, outputs=prediction)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsC9rtNzdajW"
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyelRnh0ece-"
      },
      "source": [
        "#assigning cost/loss function and optimization\n",
        "#cost/loss function: categorical_crossentropy\n",
        "#optimizer: adams\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNhZ77JpfU2y"
      },
      "source": [
        "#importing images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBYqn_X2iOOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b9cca7-227e-46e5-f2ab-d4137ecd8a3f"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/real vs fake/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 100,\n",
        "                                                 class_mode = 'categorical')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15024 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRP618gKVUVv",
        "outputId": "4d3f633e-9b24-4933-828e-0ca340cfd248"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/real vs fake/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 100,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_UMLggChDGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1a12e5-0fb2-4e2a-afe2-24ac3f3ac62f"
      },
      "source": [
        "#fit the model\n",
        "r = model.fit(\n",
        "    training_set, \n",
        "    validation_data = test_set,\n",
        "    epochs = 15,\n",
        "    steps_per_epoch = len(training_set),\n",
        "    validation_steps = len(test_set)\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "151/151 [==============================] - 7899s 52s/step - loss: 0.4537 - accuracy: 0.8757 - val_loss: 0.1534 - val_accuracy: 0.9430\n",
            "Epoch 2/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.1217 - accuracy: 0.9554 - val_loss: 0.1123 - val_accuracy: 0.9636\n",
            "Epoch 3/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0883 - accuracy: 0.9691 - val_loss: 0.0548 - val_accuracy: 0.9790\n",
            "Epoch 4/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 0.0568 - val_accuracy: 0.9827\n",
            "Epoch 5/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0698 - accuracy: 0.9763 - val_loss: 0.2184 - val_accuracy: 0.9091\n",
            "Epoch 6/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.0364 - val_accuracy: 0.9891\n",
            "Epoch 7/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.0649 - val_accuracy: 0.9785\n",
            "Epoch 8/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.0365 - val_accuracy: 0.9858\n",
            "Epoch 9/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0347 - val_accuracy: 0.9895\n",
            "Epoch 10/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0604 - val_accuracy: 0.9788\n",
            "Epoch 11/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0587 - val_accuracy: 0.9801\n",
            "Epoch 12/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0400 - accuracy: 0.9853 - val_loss: 0.0389 - val_accuracy: 0.9877\n",
            "Epoch 13/15\n",
            "151/151 [==============================] - 212s 1s/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.0174 - val_accuracy: 0.9947\n",
            "Epoch 14/15\n",
            "151/151 [==============================] - 211s 1s/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0230 - val_accuracy: 0.9934\n",
            "Epoch 15/15\n",
            "151/151 [==============================] - 209s 1s/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0180 - val_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2MGCXbA11T4"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLlqDhrb1l6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "3e0aa6c5-3bb8-455a-f47e-12b6e14df022"
      },
      "source": [
        "\n",
        "\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-239b47bbe9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plot the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
          ]
        }
      ]
    }
  ]
}